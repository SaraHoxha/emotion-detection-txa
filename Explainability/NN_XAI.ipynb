{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install tf_explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/sara/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "original_sys_path = sys.path.copy()\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../general_utils'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from preprocessing import *\n",
    "from nn_utils import *\n",
    "\n",
    "sys.path = original_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "df_train = pd.read_csv('../Model Implementation/data/train_yangswei_85.csv')  \n",
    "# Load test set\n",
    "test_df = pd.read_csv('../Model Implementation/data/test_yangswei_85.csv')\n",
    "dataset_name = 'Yangswei_85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'].apply(preprocess).to_frame()\n",
    "\n",
    "# Tokenize and pad training data\n",
    "padded_sequences, tokenizer, vocab_size = tokenize_and_pad(df_train[['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "num_classes = 6\n",
    "test_df['text'].apply(preprocess).to_frame()  \n",
    "\n",
    "# Tokenize and pad test data using the same tokenizer from training\n",
    "padded_test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "padded_test_sequences = tf.keras.preprocessing.sequence.pad_sequences(padded_test_sequences, maxlen=padded_sequences.shape[1])\n",
    "\n",
    "# Tokenize and pad test data\n",
    "padded_sequences, _, _ = tokenize_and_pad(test_df[['text']])\n",
    "\n",
    "# Set test data\n",
    "test_data = padded_sequences\n",
    "\n",
    "#Encode test labels by loading encoder used for training labels\n",
    "true_labels = test_df['label']\n",
    "label_classes = np.load('../Model Implementation/data/label_classes.npy', allow_pickle=True)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = label_classes\n",
    "test_labels = torch.tensor(label_encoder.transform(true_labels))\n",
    "test_labels_one_hot_encoded = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = \".h5\"  # Replace with your .h5 file path\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(padded_test_sequences, test_labels_one_hot_encoded, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "predictions_probabilities = model.predict(padded_test_sequences)\n",
    "predicted_classes = label_encoder.inverse_transform(np.argmax(predictions_probabilities, axis=1))\n",
    "true_classes = label_encoder.inverse_transform(np.argmax(test_labels_one_hot_encoded, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the test instances, true labels, and predicted labels\n",
    "results_df = test_df['text'].copy()\n",
    "results_df['true_label'] = true_labels.values\n",
    "results_df['predicted_label'] = predicted_classes\n",
    "\n",
    "# Filter to find correctly predicted instances\n",
    "correct_predictions = results_df[results_df['true_label'] == results_df['predicted_label']]\n",
    "print(\"Correctly predicted instances:\\n\", correct_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradCAM\n",
    "explainer = GradCAM()\n",
    "\n",
    "# Define the target layer to explain (adjust according to your model)\n",
    "# This should be the name of the last convolutional layer or a layer of interest\n",
    "target_layer_name = \"last_conv_layer_name\"  # Replace with actual layer name in your model\n",
    "\n",
    "# Run the explainer\n",
    "explanations = explainer.explain(\n",
    "    validation_data=(input_data, None),  # Input data and optional labels\n",
    "    model=model,\n",
    "    layer_name=target_layer_name\n",
    ")\n",
    "\n",
    "# Save or display the output\n",
    "explainer.save(explanations, \".\", \"grad_cam_output.png\")\n",
    "\n",
    "# Display the visualization\n",
    "plt.imshow(explanations)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP Explainer\n",
    "explainer = shap.Explainer(model, input_data)\n",
    "\n",
    "# Generate SHAP values\n",
    "shap_values = explainer(input_data)\n",
    "\n",
    "# Visualize explanations using SHAP\n",
    "shap.summary_plot(shap_values, input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
