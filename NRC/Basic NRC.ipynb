{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0145bf3-1cc1-426d-8144-250f9cb3bbc1",
   "metadata": {},
   "source": [
    "# Predict the Emotion Labels based on the Basic NRC Emotion Lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd325537-b2a1-4d99-90e7-18aa1c6cba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542d316-6889-4e00-83ec-376d84d0891d",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202e3500-5464-4a81-b505-449a34d2592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_t5 = r\"..\\Model Implementation\\data\\test_t5.csv\"\n",
    "t5_test = pd.read_csv(file_path_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd606752-5923-48e7-861b-36a807d22a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_yangswei_85 = r\"..\\Model Implementation\\data\\test_yangswei_85.csv\"\n",
    "yangswei_85_test = pd.read_csv(file_path_yangswei_85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee5ef8-9957-41ed-bf86-b4012145c83f",
   "metadata": {},
   "source": [
    "## NRC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c9233-19d8-4485-824c-332f28e14ebe",
   "metadata": {},
   "source": [
    "This function reads the NRC Emotion Lexicon file and constructs a dictionary where each word is mapped to its associated emotions and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07995573-dfa9-4b9a-8ba4-186cb07ba952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nrc_lexicon(file_path):\n",
    "    lexicon = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                word, emotion, intensity = parts\n",
    "                intensity = float(intensity)\n",
    "                if word not in lexicon:\n",
    "                    lexicon[word] = {}\n",
    "                lexicon[word][emotion] = intensity\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6bead5-53d0-4f9b-a1bf-dd0e2f1c9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NRC Lexicon\n",
    "nrc_file_path = 'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'  \n",
    "nrc_lexicon = load_nrc_lexicon(nrc_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32360966-7b82-4cf2-8bbf-94631a6adb98",
   "metadata": {},
   "source": [
    "The predict_emotion function is used to predict the emotion of a given text based on the NRC Emotion Lexicon. It calculates the emotion scores for each word in the text and returns the emotion with the highest score, as well as the scores for all emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c996e3a7-c506-4407-aeb2-70ba90c4c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted label before\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict emotion function\n",
    "def predict_emotion(text, nrc_lexicon):\n",
    "    words = text.split()\n",
    "    emotion_scores = {emotion: 0 for emotion in ['anger', 'fear', 'joy', 'sadness', 'surprise', 'trust', 'anticipation', 'disgust']}  # Define emotion categories\n",
    "\n",
    "    # Calculate emotion scores for each word in the text\n",
    "    for word in words:\n",
    "        word = word.lower()  # Convert to lowercase to match NRC lexicon\n",
    "        if word in nrc_lexicon:\n",
    "            for emotion, score in nrc_lexicon[word].items():\n",
    "                if emotion in emotion_scores:\n",
    "                    emotion_scores[emotion] += score  # Accumulate score for the emotion\n",
    "\n",
    "    # Assign emotion with the highest score\n",
    "    if sum(emotion_scores.values()) > 0:  # If scores are non-zero\n",
    "        predicted_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "    else:\n",
    "        # Use mode of previous predictions if no emotion scores are found\n",
    "        if predicted_labels:\n",
    "            predicted_emotion = Counter(predicted_labels).most_common(1)[0][0]\n",
    "\n",
    "    # Store the predicted label for mode calculation\n",
    "    predicted_labels.append(predicted_emotion)\n",
    "    \n",
    "    return predicted_emotion, emotion_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e8f7ef-cc97-456d-9014-872fad2b08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict label by NRC Lexicon\n",
    "yangswei_85_test['predicted_emotion'], yangswei_85_test['emotion_scores'] = zip(*yangswei_85_test['text'].apply(lambda x: predict_emotion(x, nrc_lexicon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd4e89e-29d6-42ad-9680-7fb6fa01b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict label by NRC Lexicon\n",
    "t5_test['predicted_emotion'], t5_test['emotion_scores'] = zip(*t5_test['text'].apply(lambda x: predict_emotion(x, nrc_lexicon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00bc8d-7b66-4024-ae66-d6a716f143d1",
   "metadata": {},
   "source": [
    "## Convert to Parrott's emotion¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbebef-845b-403b-b8e6-55eb1e5bbf7f",
   "metadata": {},
   "source": [
    "After predicting the NRC labels, we mapped our results to Parrott's emotion categories based on the definitions provided in the groups listed at  https://en.wikipedia.org/wiki/Emotion_classification. This mapping was an attempt to align the NRC emotions with Parrott's emotions to observe their correspondence.\n",
    "In this approach, we highlighted some changes as below:\n",
    "1. In class \"joy\" in Parrott's emotion, there are two sub-emotions: \"eagerness\" and \"hope.\" These emotions share similar meanings with \"anticipation\" from the NRC lexicon, so we decided to convert it into \"joy.\"\n",
    "2. In class \"anger\" in Parrott's emotion, there is the \"disgust\" in this list, so we decided to convert it into \"anger\"\n",
    "3. In class \"love\" in Parrott's emotion, we added \"trust\" because it’s an important part of love. Trust helps build strong, loving relationships, so we included it under \"love\" to show how essential it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6568448-6092-4aa1-a798-73d198d394b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_nrc_to_parrott(nrc_emotion):\n",
    "    mapping = {\n",
    "        \"anger\": \"anger\",\n",
    "        \"anticipation\": \"joy\",  # convert Anticipation to Joy\n",
    "        \"disgust\": \"anger\",   # convert Disgust to Anger\n",
    "        \"fear\": \"fear\",\n",
    "        \"joy\": \"joy\",\n",
    "        \"sadness\": \"sadness\",\n",
    "        \"surprise\": \"surprise\",\n",
    "        \"trust\": \"love\",         # convert Trust to Love\n",
    "    }\n",
    "    return mapping.get(nrc_emotion, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b074cf3d-8771-47d2-89ff-dbae241bcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the NRC's emotion label to the Parrott's emotion label\n",
    "t5_test['map_to_parrott'] = t5_test['predicted_emotion'].apply(map_nrc_to_parrott)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121e110c-932e-48f4-9725-cd71c67afc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the NRC's emotion label to the Parrott's emotion label\n",
    "yangswei_85_test['map_to_parrott'] = yangswei_85_test['predicted_emotion'].apply(map_nrc_to_parrott)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00f78a3-4c3c-4e2e-a099-dbbad52a492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map_to_parrott\n",
       "joy         10488\n",
       "love         5736\n",
       "anger        3536\n",
       "fear         2342\n",
       "sadness      1818\n",
       "surprise      554\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of label after predicting with t5 dataset\n",
    "t5_test['map_to_parrott'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a201e684-3a87-4741-b517-870679fdb1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map_to_parrott\n",
       "joy         9534\n",
       "love        5114\n",
       "anger       3318\n",
       "fear        2101\n",
       "sadness     1683\n",
       "surprise     539\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of label after predicting with yangswei_85 dataset\n",
    "yangswei_85_test['map_to_parrott'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b3100-4760-4914-868b-6204d51aecf8",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4f7d70-aa8d-45b4-b100-d50a3b297e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
    "        'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755244a0-9671-493b-8259-155cc4598ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3301462776824385,\n",
       " 'precision': 0.4256384563291098,\n",
       " 'recall': 0.3301462776824385,\n",
       " 'f1': 0.3628026551610573}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of t5 dataset\n",
    "y_true_t5 = t5_test['label']\n",
    "y_pred_t5 = t5_test['map_to_parrott']\n",
    "t5_metrics_map_to_parrott = calculate_metrics(y_true_t5, y_pred_t5)\n",
    "t5_metrics_map_to_parrott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a17c69-eb60-451f-924a-3fb19faa1660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.3637220153438916,\n",
       " 'precision': 0.5081070224323526,\n",
       " 'recall': 0.3637220153438916,\n",
       " 'f1': 0.41795279824908305}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of yangswei_85 dataset\n",
    "y_true_yangswei_85_test = yangswei_85_test['label']\n",
    "y_pred_yangswei_85_test = yangswei_85_test['map_to_parrott']\n",
    "yangswei_85_metrics_map_to_parrott = calculate_metrics(y_true_yangswei_85_test, y_pred_yangswei_85_test)\n",
    "yangswei_85_metrics_map_to_parrott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a053e22-fb10-449b-adca-e11e7a0fecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics to the result file\n",
    "def save_metrics_to_file(metrics, filename):\n",
    "    metrics_str = (f\"Accuracy: {metrics['accuracy']:.4f}\\n\"\n",
    "        f\"Precision: {metrics['precision']:.4f}\\n\"\n",
    "        f\"Recall: {metrics['recall']:.4f}\\n\"\n",
    "        f\"F1-Score: {metrics['f1']:.4f}\\n\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(metrics_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401d0a67-a8c5-480e-9f86-f3783ef41a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics_to_file(t5_metrics_map_to_parrott, 't5_metrics_nrc.txt')\n",
    "save_metrics_to_file(yangswei_85_metrics_map_to_parrott, 'yangswei_85_metrics_nrc.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
