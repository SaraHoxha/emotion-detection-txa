{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395184e5-2860-4385-9361-3f8853cd7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858d0988-48fd-4214-a2aa-f00aa54ddc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec38462f-1ca1-4666-bfa4-b578e5118536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter Blues and WFH question i think the sudd...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Workspace i saw some of your other posts a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard to mentally unwind… i go for a long walk ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would you leave 150k for 90k depends on your e...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There’s no magic formula to get remote work so...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Winter Blues and WFH question i think the sudd...  anger\n",
       "1  New Workspace i saw some of your other posts a...    joy\n",
       "2  Hard to mentally unwind… i go for a long walk ...    joy\n",
       "3  Would you leave 150k for 90k depends on your e...    joy\n",
       "4  There’s no magic formula to get remote work so...   fear"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_test = pd.read_csv('test_t5.csv')\n",
    "\n",
    "t5_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c64e8598-e431-4921-a89c-82ad408020e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_path = 'NRC-Emotion-Intensity-Lexicon-v1.txt'\n",
    "\n",
    "def load_nrc_lexicon(file_path):\n",
    "    lexicon = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                word, emotion, intensity = parts\n",
    "                intensity = float(intensity)\n",
    "                if word not in lexicon:\n",
    "                    lexicon[word] = {}\n",
    "                lexicon[word][emotion] = intensity\n",
    "    return lexicon\n",
    "nrc_lexicon = load_nrc_lexicon(lexicon_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c54ff2f-ef1c-45e8-a3e1-d95402bca4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text, lexicon):\n",
    "    \n",
    "    # create the dict to store the score for each emotion\n",
    "    emotion_scores = {emotion: 0 for emotion in set(e for values in lexicon.values() for e in values)}\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # calculate the score of emotion based on lexicon\n",
    "    for word in words:\n",
    "        if word in lexicon:\n",
    "            for emotion, intensity in lexicon[word].items():\n",
    "                emotion_scores[emotion] += intensity\n",
    "                \n",
    "    # choose the emotion with the highest score\n",
    "    max_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "    return max_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "151202a2-7aec-4395-9d51-a7aae89409ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_nrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter Blues and WFH question i think the sudd...</td>\n",
       "      <td>anger</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Workspace i saw some of your other posts a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard to mentally unwind… i go for a long walk ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Would you leave 150k for 90k depends on your e...</td>\n",
       "      <td>joy</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There’s no magic formula to get remote work so...</td>\n",
       "      <td>fear</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_nrc\n",
       "0  Winter Blues and WFH question i think the sudd...  anger  surprise\n",
       "1  New Workspace i saw some of your other posts a...    joy       joy\n",
       "2  Hard to mentally unwind… i go for a long walk ...    joy       joy\n",
       "3  Would you leave 150k for 90k depends on your e...    joy   sadness\n",
       "4  There’s no magic formula to get remote work so...   fear   sadness"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict label by NRC\n",
    "t5_test['label_nrc'] = t5_test['text'].apply(lambda x: label_text(x, nrc_lexicon))\n",
    "\n",
    "t5_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f458c0-ef02-4e30-a2d0-e7562b4fc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test.to_csv('t5_nrc_inten_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857c07f9-5cd7-4ba7-804e-94cd392b7511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_nrc\n",
       "trust           8034\n",
       "joy             5861\n",
       "anticipation    3691\n",
       "fear            3243\n",
       "sadness         1911\n",
       "anger            924\n",
       "disgust          495\n",
       "surprise         315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = t5_test['label_nrc'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c55baa99-1b44-4dbc-aa69-fd8c599f1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for NRC:\n",
      "Accuracy: 0.2211\n",
      "Precision: 0.5155\n",
      "Recall: 0.2211\n",
      "F1-Score: 0.2860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\minhd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "y_true = t5_test['label']\n",
    "y_pred = t5_test['label_nrc']\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# show the results\n",
    "print(\"Metrics for NRC:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ddd634-17f8-4775-a247-f7648019fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_nrc_to_parrott(nrc_emotion):\n",
    "    mapping = {\n",
    "        \"anger\": \"anger\",\n",
    "        \"anticipation\": \"joy\",  # convert Anticipation to Joy\n",
    "        \"disgust\": \"sadness\",   # convert Disgust to Sadness\n",
    "        \"fear\": \"fear\",\n",
    "        \"joy\": \"joy\",\n",
    "        \"sadness\": \"sadness\",\n",
    "        \"surprise\": \"surprise\",\n",
    "        \"trust\": \"love\",         # convert Trust to Love\n",
    "        \"neutral\" : \"neutral\" # keep the same for unpredicted labels\n",
    "    }\n",
    "    return mapping.get(nrc_emotion, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77d0e5e-cc31-4074-9fd1-10064c6f66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test['map_to_parrott'] = t5_test['label_nrc'].apply(map_nrc_to_parrott)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e66d32f5-3f94-41c0-a630-50cd6d3b1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
    "        'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6401195d-4e73-4228-bc4a-099c7936b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_t5 = t5_test['label']\n",
    "y_pred_t5 = t5_test['map_to_parrott']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0764e04-6c31-424b-8a18-16c7206c4a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.29100269673939694,\n",
       " 'precision': 0.48201616208766485,\n",
       " 'recall': 0.29100269673939694,\n",
       " 'f1': 0.32192057621297343}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_metrics_map_to_parrott = calculate_metrics(y_true_t5, y_pred_t5)\n",
    "t5_metrics_map_to_parrott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37671650-a13b-4d9f-9664-6d8813898df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_file(metrics, filename):\n",
    "    metrics_str = (f\"Accuracy: {metrics['accuracy']:.4f}\\n\"\n",
    "        f\"Precision: {metrics['precision']:.4f}\\n\"\n",
    "        f\"Recall: {metrics['recall']:.4f}\\n\"\n",
    "        f\"F1-Score: {metrics['f1']:.4f}\\n\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(metrics_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0285a191-ed63-4d7b-ba6e-19d2ca6d1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics_to_file(t5_metrics_map_to_parrott, 't5_metrics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d7fa26c-1381-423f-ae6f-d937e532c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test.to_csv('t5_NRC_map_to_parrott.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009099a9-e886-4154-ae28-a16473a4e41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
