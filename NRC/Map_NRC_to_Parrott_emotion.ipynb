{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "123a77ad-b701-48bc-9d79-3bb50cd9c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b634e4b5-c267-4d10-b024-7148e15ae40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test = pd.read_csv('test_t5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b660f07f-3aff-4a53-82e9-c6eac92f079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yangswei_85_test = pd.read_csv('test_yangswei_85.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3ccfe-0c4a-453f-a6e4-0d1b0dd8b56b",
   "metadata": {},
   "source": [
    "# Predict NRC's emotion and convert to Parrott's emotion based on the Parrott's emotions by groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d842066-f94a-46e7-87e4-5a51816b122c",
   "metadata": {},
   "source": [
    "Based on the definition of Parrott's emotions by groups at https://en.wikipedia.org/wiki/Emotion_classification , I tried to map the NRC emotion to the Parrott's emotion to observe their correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f43f87d-cf9f-49a0-ab82-3aa699fc4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion_nrclex_ignore_sentiments(text):\n",
    "    emotion_data = NRCLex(text)\n",
    "    # don't count \"positive\" and \"negative\" sentiment\n",
    "    filtered_emotions = {emotion: score for emotion, score in emotion_data.raw_emotion_scores.items()\n",
    "                         if emotion not in ['positive', 'negative']}\n",
    "    \n",
    "    if filtered_emotions:\n",
    "        # choose the label having the highest score\n",
    "        dominant_emotion = max(filtered_emotions, key=filtered_emotions.get)\n",
    "        return dominant_emotion\n",
    "    else:\n",
    "        return \"neutral\"  # return \"neutral if the model could not detect any emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f1362a7-9dd0-466a-943a-7cf04f0ec519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_nrc_to_parrott(nrc_emotion):\n",
    "    mapping = {\n",
    "        \"anger\": \"anger\",\n",
    "        \"anticipation\": \"joy\",  # convert Anticipation to Joy\n",
    "        \"disgust\": \"sadness\",   # convert Disgust to Sadness\n",
    "        \"fear\": \"fear\",\n",
    "        \"joy\": \"joy\",\n",
    "        \"sadness\": \"sadness\",\n",
    "        \"surprise\": \"surprise\",\n",
    "        \"trust\": \"love\",         # convert Trust to Love\n",
    "        \"neutral\" : \"neutral\" # keep the same for unpredicted labels\n",
    "    }\n",
    "    return mapping.get(nrc_emotion, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea482c76-79a6-48fb-af73-ae4755821c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
    "        'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63626ef7-0bdb-4171-a231-411538092ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_file(metrics, filename):\n",
    "    metrics_str = (f\"Accuracy: {metrics['accuracy']:.4f}\\n\"\n",
    "        f\"Precision: {metrics['precision']:.4f}\\n\"\n",
    "        f\"Recall: {metrics['recall']:.4f}\\n\"\n",
    "        f\"F1-Score: {metrics['f1']:.4f}\\n\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(metrics_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2f615-6873-46cb-ab96-8d811b5ce8a7",
   "metadata": {},
   "source": [
    "## t5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c90f16db-3fea-4b62-bfb2-c6419cc1104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test['label_nrc'] = t5_test['text'].apply(predict_emotion_nrclex_ignore_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a89ad74-fa57-4286-9533-fd9d5f0a58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_test['map_to_parrott'] = t5_test['label_nrc'].apply(map_nrc_to_parrott)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c09481ef-232e-46eb-9844-a82779835f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map_to_parrott\n",
       "joy         8230\n",
       "love        5815\n",
       "neutral     3716\n",
       "anger       2515\n",
       "sadness     2159\n",
       "fear        1548\n",
       "surprise     491\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = t5_test['map_to_parrott'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "865d6972-a634-4e0d-8f98-5cf9f1a38c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_t5 = t5_test['label']\n",
    "y_pred_t5 = t5_test['map_to_parrott']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f48784-b5a0-4ac6-bd6c-01cf01abfd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.26268693307183133,\n",
       " 'precision': 0.42847967489226385,\n",
       " 'recall': 0.26268693307183133,\n",
       " 'f1': 0.31598684885365796}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_metrics_map_to_parrott = calculate_metrics(y_true_t5, y_pred_t5)\n",
    "t5_metrics_map_to_parrott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "710c5dfc-3193-46a2-8368-6d693301d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics_to_file(t5_metrics_map_to_parrott, 't5_metrics_map_to_parrott.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96acaa1-10e4-4757-b699-16dbc7cf93e6",
   "metadata": {},
   "source": [
    "## yangswei_85 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adfd0adf-56c6-4f7b-bd48-eb40f6fec659",
   "metadata": {},
   "outputs": [],
   "source": [
    "yangswei_85_test['label_nrc'] = yangswei_85_test['text'].apply(predict_emotion_nrclex_ignore_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cfdf24a-5ff1-4974-9fd9-1838a9c4275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yangswei_85_test['map_to_parrott'] = yangswei_85_test['label_nrc'].apply(map_nrc_to_parrott)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c178e9-e131-4cc3-930b-4b5205b85218",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_yangswei_85= yangswei_85_test['label']\n",
    "y_pred_yangswei_85 = yangswei_85_test['map_to_parrott']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ab08e-6d8f-4697-b5f7-f078d6776061",
   "metadata": {},
   "outputs": [],
   "source": [
    "yangswei_85_metrics_map_to_parrott = calculate_metrics(y_true_t5, y_pred_t5)\n",
    "yangswei_85_metrics_map_to_parrott"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
